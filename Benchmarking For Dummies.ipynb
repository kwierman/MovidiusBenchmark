{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Creating a Base Benchmark for Motivating ASIC DNN Framework\n",
    "\n",
    "I'm calling this benchmarking for idiots since taking the wall clock and looking at execution time is a simplistic approach to hardware benchmarking. If we were to put some serious effort into this study, we'd get a bit closer to the metal and see what the \"production\" exection time looks like. In addition, I\"m currently working on the computer using both the CPU and GPU, so we're going to need errors bars to show what the uncertainty in our measurements looks like.\n",
    "\n",
    "First, the libraries we're going to use:\n",
    "\n",
    "* mvnc is the movidius interface library. In the future, I intend to wrap a bit of this out\n",
    "* matplotlib is being used in case we need fine control of the plotting\n",
    "* subprocess is necessary to call the movidius kernel compiler\n",
    "* tensorflow is our NN library du'jour\n",
    "* pandas is being used for data processing\n",
    "* numpy is being used to generate fake data\n",
    "* time is being used to benchmark the execution time\n",
    "* csv is being used to record incremental results\n",
    "\n",
    "* Finally, seaborn is being used to make the plots... pretty.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/kwierman/Desktop/dl_sandbox/dlenv/lib/python3.6/site-packages/tensorflow/python/framework/ops.py:849: DeprecationWarning: builtin type EagerTensor has no __module__ attribute\n",
      "  EagerTensor = c_api.TFE_Py_InitEagerTensor(_EagerTensorBase)\n",
      "/home/kwierman/Desktop/dl_sandbox/dlenv/lib/python3.6/site-packages/tensorflow/python/util/tf_inspect.py:45: DeprecationWarning: inspect.getargspec() is deprecated, use inspect.signature() or inspect.getfullargspec()\n",
      "  if d.decorator_argspec is not None), _inspect.getargspec(target))\n",
      "/home/kwierman/Desktop/dl_sandbox/dlenv/lib/python3.6/site-packages/h5py/__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n",
      "/home/kwierman/Desktop/dl_sandbox/dlenv/lib/python3.6/site-packages/tensorflow/python/util/tf_inspect.py:45: DeprecationWarning: inspect.getargspec() is deprecated, use inspect.signature() or inspect.getfullargspec()\n",
      "  if d.decorator_argspec is not None), _inspect.getargspec(target))\n"
     ]
    }
   ],
   "source": [
    "from mvnc import mvncapi as mvnc\n",
    "import matplotlib.pyplot as plt\n",
    "from subprocess import call\n",
    "import tensorflow as tf\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import time\n",
    "import csv\n",
    "\n",
    "import seaborn as sns\n",
    "\n",
    "%matplotlib notebook\n",
    "sns.set_context(\"notebook\")\n",
    "sns.set_style(\"whitegrid\")\n",
    "sns.set_palette(\"Set1\",8, 0.75)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## The Movidius Device\n",
    "Right off the bat, I'm going to make sure that movidius device is initialized properly."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "devices = mvnc.EnumerateDevices()\n",
    "if len(devices) == 0:\n",
    "    print('No devices found')\n",
    "    \n",
    "device = mvnc.Device(devices[0])\n",
    "device.OpenDevice()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Network Definition\n",
    "\n",
    "This is the perceptron network model. The idea is to do 2-class classification on 100 inputs and the intermediate layers are just 100x100 perceptron layers. In order to test latency as a function of depth, we just increase the number of hidden layers and thus parameters and measure the execution time."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def multilayer_perceptron( n_layers):\n",
    "    \"\"\" Create a multilayer perceptron network with n_layers -1 \n",
    "    layers and return the first and last node.\n",
    "    \"\"\"\n",
    "    # First Layer definition\n",
    "    X = tf.placeholder(\"float\", [None, 100], name='input')\n",
    "    x = tf.add(tf.matmul(X, tf.Variable(tf.random_normal([100, 100]))),\n",
    "                                  tf.Variable(tf.random_normal([100])))\n",
    "    # Add in layers up to n_layers\n",
    "    for _ in range(n_layers):\n",
    "        x = tf.add(tf.matmul(x, tf.Variable(tf.random_normal([100, 100]))),\n",
    "                                tf.Variable(tf.random_normal([100])))\n",
    "        \n",
    "    # Output fully connected layer with a neuron for each class\n",
    "    x = tf.add(tf.matmul(x, tf.Variable(tf.random_normal([100, 2]))),\n",
    "                                  tf.Variable(tf.random_normal([2])))\n",
    "    x = tf.nn.softmax(x, name='output')\n",
    "    return X, x"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Experiment Definition\n",
    "\n",
    "I'm going to furthermore wrap the network calls so that between the CPU and GPU execution, we won't need to write redundant code. This returns a list of execution times and the number of parameters in the network."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "save_path = None\n",
    "def run_for_layers(n_layers=1, save=False, n_iterations=100):\n",
    "    \"\"\"\n",
    "    :type n_layers: int The number of hidden layers in the network -1\n",
    "    :type save: bool Whether or not to save the checkpoint of the model\n",
    "    \"type n_iterations: int The number of experiments to repeat\n",
    "    :rtype: int, list The number of parameters and a list of the execution times for the model\n",
    "    \"\"\"\n",
    "    global save_path\n",
    "    X, logits = multilayer_perceptron(n_layers)\n",
    "    init = tf.global_variables_initializer()\n",
    "    # If we're saving the model, create a saver\n",
    "    saver = None\n",
    "    if save:\n",
    "        saver = tf.train.Saver()\n",
    "    with tf.Session() as sess:\n",
    "        # Compute out the number of parameters in this network\n",
    "        x=100*100+100+100*2+2 + n_layers*(100*100+100)\n",
    "        y=[]\n",
    "        for _ in range(n_iterations):        \n",
    "            sess.run(init)\n",
    "            # Start the clock, run the network, and then stop the network.\n",
    "            start = time.time()\n",
    "            sess.run([logits, ], feed_dict={X: np.ndarray(shape=(100, 100))})\n",
    "            end = time.time()\n",
    "            \n",
    "            y.append(end-start)\n",
    "        if save:\n",
    "            save_path = saver.save(sess, \"./model\")\n",
    "        return x, y"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Script to run the full sequence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/kwierman/Desktop/dl_sandbox/dlenv/lib/python3.6/site-packages/tensorflow/python/framework/tensor_util.py:539: DeprecationWarning: The binary mode of fromstring is deprecated, as it behaves surprisingly on unicode inputs. Use frombuffer instead\n",
      "  return np.fromstring(tensor.tensor_content, dtype=dtype).reshape(shape)\n",
      "/home/kwierman/Desktop/dl_sandbox/dlenv/lib/python3.6/site-packages/tensorflow/python/util/tf_inspect.py:45: DeprecationWarning: inspect.getargspec() is deprecated, use inspect.signature() or inspect.getfullargspec()\n",
      "  if d.decorator_argspec is not None), _inspect.getargspec(target))\n"
     ]
    }
   ],
   "source": [
    "\n",
    "with open('results.csv', 'w') as csvfile:\n",
    "    # Record the data to a csv file\n",
    "    fieldnames = ['N Params', 'Exec Time', \"Device\"]\n",
    "    writer = csv.DictWriter(csvfile, fieldnames)\n",
    "    writer.writeheader()\n",
    "    for i in range(11):\n",
    "        # Run the CPU computation\n",
    "        with tf.device('/cpu:0'):\n",
    "            x, y = run_for_layers(i*100, False, 1000)\n",
    "            for j in range(len(y)):\n",
    "                output = {'N Params':x, \n",
    "                          'Exec Time': y[j],\n",
    "                          \"Device\":\"CPU\"}\n",
    "                writer.writerow(output)\n",
    "        # Run the GPU computation\n",
    "        with tf.device('/gpu:0'):\n",
    "            x, y = run_for_layers(i*100, False, 1000)\n",
    "            for j in range(len(y)):\n",
    "                output = {'N Params':x, \n",
    "                          'Exec Time': y[j],\n",
    "                          \"Device\":\"GPU\"}\n",
    "                writer.writerow(output)\n",
    "            csvfile.flush()\n",
    "        # Run the ASIC Computation\n",
    "        with tf.device('/cpu:0'):\n",
    "            # This is required to save the network checkpoint\n",
    "            run_for_layers(i*100, True, 1)\n",
    "        # Compile the checkpoint into something the Movidius stick can understand\n",
    "        call(['/usr/local/bin/mvNCCompile','model.meta','-w','model',\n",
    "              '-s','12','-in','input','-on','output','-o','model.graph'])\n",
    "        \n",
    "        with open('./model.graph', mode='rb') as f:    \n",
    "            # Load the model onto the stick\n",
    "            graphfile = f.read()\n",
    "            graph = device.AllocateGraph(graphfile)\n",
    "            x=[]\n",
    "            y=[]\n",
    "            for j in range(1000):\n",
    "                # Start the clock, move data over, then get the results and stop the clock.\n",
    "                start = time.time()\n",
    "                graph.LoadTensor(np.ndarray(shape=(100, 100)), 'user object')\n",
    "                output, userobj = graph.GetResult()\n",
    "                end = time.time()\n",
    "                output = {'N Params': 100*100+100+100*2+2 + 100*i*(100*100+100), \n",
    "                          'Exec Time': end-start,\n",
    "                          \"Device\":\"ASIC\"}\n",
    "                writer.writerow(output)\n",
    "            # Don't forget to cleanup!\n",
    "            graph.DeallocateGraph()\n",
    "            \n",
    "            csvfile.flush()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Plotting \n",
    "\n",
    "We're going to plot the execution time as a function of number of parameters. Separate results on device type, and prettify the plot.\n",
    "\n",
    "To that end, we'll use seaborn, since this is the 1-line solution."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"results.csv\")\n",
    "ax = sns.pointplot(x=\"N Params\", y=\"Exec Time\", hue=\"Device\", data=df)\n",
    "locs, labels = plt.xticks()\n",
    "plt.setp(labels, rotation=45)\n",
    "plt.xlabel(\"Number of Network Parameters\")\n",
    "plt.ylabel(\"Execution Time [s]\")\n",
    "plt.tight_layout()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For Completeness, the following devices were used in this study.\n",
    "\n",
    "CPU: Intel® Core™ i7-5500U CPU @ 2.40GHz × 4 \n",
    "\n",
    "GPU: GeForce GTX 950M/PCIe/SSE2\n",
    "\n",
    "ASIC: Intel Movidius Neural Compute Stick"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
